"""
å®¡æ ¸è€…Agent - è´Ÿè´£é€‰æ‹©é—®é¢˜ã€æ ¸å®ç­”æ¡ˆã€æ•´åˆæŠ¥å‘Š
"""

import logging
import re
from typing import Dict, List
from graph.state import PaperAnalysisState
from utils.llm_client import LLMClient
from agents.prompts import (
    build_reviewer_select_questions_prompt,
    build_reviewer_verify_prompt,
    build_reviewer_final_integration_prompt
)


logger = logging.getLogger(__name__)


def select_questions(state: PaperAnalysisState, llm_client: LLMClient) -> Dict:
    """
    é€‰æ‹©Nä¸ªé‡è¦é—®é¢˜ï¼ˆæ ¹æ®é…ç½®ä¸­çš„ num_questionsï¼‰

    Args:
        state: å½“å‰çŠ¶æ€
        llm_client: LLMå®¢æˆ·ç«¯

    Returns:
        Dict: æ›´æ–°åçš„çŠ¶æ€å­—æ®µ
    """
    logger.info("Reviewer: Selecting questions...")

    paper_structure = state['paper_structure']
    num_questions = state.get('total_questions', 3)  # ä»çŠ¶æ€ä¸­è·å–é…ç½®çš„é—®é¢˜æ•°é‡

    # æ„å»ºprompt
    prompt = build_reviewer_select_questions_prompt(paper_structure, num_questions)

    # è°ƒç”¨LLM
    questions_text = llm_client.call_reviewer(prompt)

    # è§£æé—®é¢˜
    questions = parse_questions(questions_text, num_questions)

    logger.info(f"Reviewer: Selected {len(questions)} questions")

    return {
        'selected_questions': questions,
        'messages': [{
            'role': 'reviewer',
            'content': questions_text,
            'round': 0,
            'question_id': 0
        }]
    }


def verify_answer(
    state: PaperAnalysisState,
    llm_client: LLMClient,
    question: str,
    answer: str,
    question_id: int
) -> Dict:
    """
    æ ¸å®åˆ†æè€…çš„ç­”æ¡ˆ

    Args:
        state: å½“å‰çŠ¶æ€
        llm_client: LLMå®¢æˆ·ç«¯
        question: é—®é¢˜
        answer: åˆ†æè€…çš„ç­”æ¡ˆ
        question_id: é—®é¢˜ç¼–å·

    Returns:
        Dict: åŒ…å«æ ¸å®ç»“æœçš„å­—å…¸
    """
    logger.info(f"Reviewer: Verifying answer for question {question_id}...")

    paper_content = state['paper_content']

    # æ„å»ºprompt
    prompt = build_reviewer_verify_prompt(question, answer, paper_content)

    # è°ƒç”¨LLM
    verification_result = llm_client.call_reviewer(prompt)

    # è§£æç»“æœ
    is_accurate, needs_followup, followup_question = parse_verification_result(verification_result)

    logger.info(f"Reviewer: Verification complete. Accurate: {is_accurate}, Needs followup: {needs_followup}")

    return {
        'verification_result': verification_result,
        'is_accurate': is_accurate,
        'needs_followup': needs_followup,
        'followup_question': followup_question,
        'messages': [{
            'role': 'reviewer',
            'content': verification_result,
            'round': state['current_round'],
            'question_id': question_id
        }]
    }


def integrate_final_report(state: PaperAnalysisState, llm_client: LLMClient) -> Dict:
    """
    æ•´åˆæœ€ç»ˆæŠ¥å‘Š

    Args:
        state: å½“å‰çŠ¶æ€
        llm_client: LLMå®¢æˆ·ç«¯

    Returns:
        Dict: æ›´æ–°åçš„çŠ¶æ€å­—æ®µ
    """
    logger.info("Reviewer: Integrating final report...")

    # æ ¼å¼åŒ–å¯¹è¯å†å²
    qa_history = format_qa_history(state['messages'])

    # æ„å»ºprompt
    prompt = build_reviewer_final_integration_prompt(qa_history)

    # è¯»å–é…ç½®ï¼Œå†³å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
    config = state.get('config', {})
    workflow_config = config.get('workflow', {})
    integration_model = workflow_config.get('final_integration_model', 'reviewer')

    # éªŒè¯é…ç½®å€¼
    if integration_model not in ['reviewer', 'analyzer']:
        logger.warning(f"Invalid final_integration_model: {integration_model}, defaulting to 'reviewer'")
        integration_model = 'reviewer'

    # æ ¹æ®é…ç½®é€‰æ‹©æ¨¡å‹
    if integration_model == 'analyzer':
        logger.info("ğŸ”¬ Using strong model (analyzer) for final integration - deep analysis mode")
        print("ğŸ”¬ ä½¿ç”¨å¼ºæ¨¡å‹æ•´åˆæŠ¥å‘Šï¼ˆæ·±åº¦åˆ†ææ¨¡å¼ï¼‰...")
        # ä½¿ç”¨å¼ºæ¨¡å‹ï¼Œtemperature ç¨é«˜ä»¥è·å¾—æ›´å¥½çš„åˆ›é€ æ€§
        final_report = llm_client.call_analyzer(prompt, temperature=0.3)
    else:
        logger.info("âš¡ Using fast model (reviewer) for final integration - quick mode")
        print("âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å‹æ•´åˆæŠ¥å‘Šï¼ˆå¿«é€Ÿç”Ÿæˆæ¨¡å¼ï¼‰...")
        # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
        final_report = llm_client.call_reviewer(prompt)

    logger.info(f"Reviewer: Final report generated. Length: {len(final_report)}")

    import time
    return {
        'final_report': final_report,
        'end_time': time.time()
    }


# ==================== è¾…åŠ©å‡½æ•° ====================

def parse_questions(questions_text: str, num_questions: int = 3) -> List[str]:
    """ä»LLMè¾“å‡ºä¸­è§£æé—®é¢˜åˆ—è¡¨

    Args:
        questions_text: LLMè¿”å›çš„é—®é¢˜æ–‡æœ¬
        num_questions: æœŸæœ›çš„é—®é¢˜æ•°é‡

    Returns:
        List[str]: è§£æå‡ºçš„é—®é¢˜åˆ—è¡¨
    """
    questions = []

    # å°è¯•åŒ¹é…"é—®é¢˜1: ...", "é—®é¢˜2: ..."æ ¼å¼
    pattern = r'é—®é¢˜\d+[:ï¼š]\s*(.+?)(?=\né—®é¢˜\d+[:ï¼š]|\Z)'
    matches = re.findall(pattern, questions_text, re.DOTALL)

    if matches:
        questions = [q.strip() for q in matches]
    else:
        # å¤‡é€‰æ–¹æ¡ˆï¼šæŒ‰è¡Œåˆ†å‰²
        lines = [line.strip() for line in questions_text.split('\n') if line.strip()]
        questions = [line for line in lines if len(line) > 10]  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ

    return questions[:num_questions]  # å–å‰Nä¸ªï¼ˆNç”±é…ç½®å†³å®šï¼‰


def parse_verification_result(verification_text: str) -> tuple:
    """
    è§£ææ ¸å®ç»“æœ

    Returns:
        tuple: (is_accurate, needs_followup, followup_question)
    """
    # é»˜è®¤å€¼
    is_accurate = True
    needs_followup = False
    followup_question = ""

    # åˆ¤æ–­å‡†ç¡®æ€§
    if 'ä¸å‡†ç¡®' in verification_text or 'éƒ¨åˆ†å‡†ç¡®' in verification_text:
        is_accurate = False

    # åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®
    if 'éœ€è¦è¿½é—®ï¼šæ˜¯' in verification_text or 'æ˜¯å¦éœ€è¦è¿½é—®ï¼šæ˜¯' in verification_text:
        needs_followup = True

        # æå–è¿½é—®å†…å®¹
        followup_pattern = r'è¿½é—®å†…å®¹[:ï¼š]\s*(.+?)(?=\n|$)'
        match = re.search(followup_pattern, verification_text, re.DOTALL)
        if match:
            followup_question = match.group(1).strip()

    return is_accurate, needs_followup, followup_question


def format_qa_history(messages: List[Dict]) -> str:
    """æ ¼å¼åŒ–å¯¹è¯å†å²"""
    formatted = "# å¯¹è¯è®°å½•\n\n"

    # æŒ‰é—®é¢˜åˆ†ç»„
    for i in range(0, len(messages), 2):
        if i + 1 < len(messages):
            question_msg = messages[i]
            answer_msg = messages[i + 1]

            formatted += f"## é—®é¢˜ {question_msg['question_id']}\n\n"
            formatted += f"**é—®é¢˜**ï¼š{question_msg['content']}\n\n"
            formatted += f"**å›ç­”**ï¼š{answer_msg['content']}\n\n"
            formatted += "---\n\n"

    return formatted
